Job ID,Experiment Name,Model,Dataset,Training Set Size,Test Set Size,Method,GPU,Learning Rate,Batch Size,Num Epochs,Lora Rank,Training Time,Spearman Rho,MSE Loss,Max GPU Memory
14234850,Baseline_Doud_Full,ESM-2 650M,Doud_NCAP,7569,1893,Full-Fine Tuning,NVIDIA A100-PCIE-40GB (39 GB),1.00E-05,4,5,NA,31m 5s,0.3221,1.3619,15.84
14235416,Baseline_RNC_ECOLI_LoRA,ESM-2 650M,RNC_ECOLI_Weeks_2023,3421,856,LoRA,NVIDIA A100-PCIE-40GB (39 GB),1.00E-04,4,3,16,12m 40s,0.6863,0.1089,9.47
